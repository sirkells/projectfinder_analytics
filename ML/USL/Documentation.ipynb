{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOCUMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the dataset from mongoDB database and store it as a pandas dataframe. <br/>\n",
    "2. Reduce the orginial dataframe by removing the columns which are not needed for Topic Modelling. Cureently we are considering only the area and the description of the project as the columns in our dataframe. \n",
    "3. Identifying stopwords:\n",
    "3.1. Load NLTK's English and German stopwords\n",
    "3.2. Add cities and mothns to it \n",
    "3.3. Manually added stopwords (irrelevant words for our analysis)\n",
    "4. Creation of Stemmer: Creating our own stemmer as a dictionary where we specify how to combine same words\n",
    "5. Tokenzing and Stemming the description data present in the dataframe.\n",
    "6. Get frequency distribution of all words present in the dataframe.\n",
    "7. Choose a threshold frequency for top words(currently 100)\n",
    "8. Reduce the words in tokenized column to these top words for each row\n",
    "9. Remove the rows which have less than 10 tokens\n",
    "10. Create training and test dataset\n",
    "11. Train LDA model\n",
    "12. Save the model as 'LDA_Approach_1.model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the dataset from mongoDB database and store it as a pandas dataframe. <br/>\n",
    "2. Reduce the orginial dataframe by removing the columns which are not needed for Topic Modelling. Cureently we are considering only the area and the description of the project as the columns in our dataframe. \n",
    "3. Perform tokenization by removing spaces and punctuations\n",
    "3. Identifying stopwords:\n",
    "3.1. Load NLTK's English and German stopwords\n",
    "3.2. Add cities and mothns to it \n",
    "3.3. Manually added stopwords (irrelevant words for our analysis)\n",
    "4. Create a new column having tokens without stopwords\n",
    "5. Generate bigrams from tokens containing stopwords and apply the bigrams to the tokens without stopwords.\n",
    "6. Store the new tokens with bigrams in a separate column.\n",
    "7. Store all bigrams into  file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the dataset from mongoDB database and store it as a pandas dataframe. <br/>\n",
    "2. Reduce the orginial dataframe by removing the columns which are not needed for Topic Modelling. Cureently we are considering only the area and the description of the project as the columns in our dataframe. \n",
    "3. Perform tokenization by removing spaces and punctuations\n",
    "4. Perform stemming with manual stemmer and store in new column\n",
    "5. Remove stopwords and store in new column\n",
    "6. Generate bigrams with tokenized and stemmed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the dataset from mongoDB database and store it as a pandas dataframe. <br/>\n",
    "2. Reduce the orginial dataframe by removing the columns which are not needed for Topic Modelling. Cureently we are considering only the area and the description of the project as the columns in our dataframe. \n",
    "3. Identifying stopwords:\n",
    "3.1. Load NLTK's English and German stopwords\n",
    "3.2. Add cities and mothns to it \n",
    "3.3. Manually added stopwords (irrelevant words for our analysis)\n",
    "4. Creation of Stemmer: Creating our own stemmer as a dictionary where we specify how to combine same words\n",
    "5. Tokenzing and Stemming the description data present in the dataframe.\n",
    "6. Generate bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
