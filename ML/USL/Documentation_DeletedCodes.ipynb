{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOCUMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH R1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the dataset from mongoDB database and store it as a pandas dataframe. <br/>\n",
    "2. Reduce the orginial dataframe by removing the columns which are not needed for Topic Modelling. Cureently we are considering only the area and the description of the project as the columns in our dataframe. \n",
    "3. Perform tokenization by removing spaces and punctuations\n",
    "3. Identifying stopwords:\n",
    "    1. Load NLTK's English and German stopwords\n",
    "    2. Add cities and mothns to it \n",
    "    3. Manually added stopwords (irrelevant words for our analysis)\n",
    "4. Create a new column having tokens without stopwords\n",
    "5. Generate bigrams from tokens containing stopwords and apply the bigrams to the tokens without stopwords.\n",
    "6. Store the new tokens with bigrams in a separate column.\n",
    "7. Store all bigrams into  file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the dataset from mongoDB database and store it as a pandas dataframe. <br/>\n",
    "2. Reduce the orginial dataframe by removing the columns which are not needed for Topic Modelling. Cureently we are considering only the area and the description of the project as the columns in our dataframe. \n",
    "3. Perform tokenization by removing spaces and punctuations\n",
    "4. Perform stemming with manual stemmer and store in new column\n",
    "5. Remove stopwords and store in new column\n",
    "6. Generate bigrams with tokenized and stemmed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the dataset from mongoDB database and store it as a pandas dataframe. <br/>\n",
    "2. Reduce the orginial dataframe by removing the columns which are not needed for Topic Modelling. Cureently we are considering only the area and the description of the project as the columns in our dataframe. \n",
    "3. Identifying stopwords:\n",
    "3.1. Load NLTK's English and German stopwords\n",
    "3.2. Add cities and mothns to it \n",
    "3.3. Manually added stopwords (irrelevant words for our analysis)\n",
    "4. Creation of Stemmer: Creating our own stemmer as a dictionary where we specify how to combine same words\n",
    "5. Tokenzing and Stemming the description data present in the dataframe.\n",
    "6. Generate bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
